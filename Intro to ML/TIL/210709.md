오늘 공부한 내용 요약 (99p ~ 117p)
1. 나이브 베이즈 분류기 (GaussianNB , BernoulliNB ,MultinomialNB)
선형 모델과 유사함. 속도가 더 빠른 편이지만 일반화 성능은 조금 떨어진다. 
효과적인 이유는 각 특성을 개별로 취급해 파라미터를 학습하고, 각 특성에서 클래스별 통계를 단순하게 취합하기 때문이다. 예를들어 BernoulliNB분류기는 각 클래스의 특성 중 0이 아닌 것이 몇개인 지 셉니다.
- BernoulliNB 예시
```python 
X = np.array([[0,1,0,1],[1,0,1,1],[0,0,0,1],[1,0,1,0]])
y = np.array([0,1,0,1])

counts = {}
for label in np.unique(y):
   #각 클래스에 대해 반복
   #특성마다 1이 나타난 횟수를 센다.
   counts[label] = X[y == label].sum(axis=0)
print("특성 카운트:\n", counts)
```
Output : {0:array([0,1,0,2]), 1:array([2,0,2,1])}

- GaussianNB 는 대부분 고차원 데이터셋에 사용, 나머지 두가지는 희소한 데이터(eg. text data)에 사용된다. 


2. 결정 트리
- 쉽게 말해 스무고개 놀이의 질문과 비슷하다. 각 셀마다의 질문을 기점으로 데이터들이 나무형태로 가지쳐지면서 내려가는 구조다.
보통은 가장 많이 나뉘게 하는 것을 루트 노드(전체 데이터셋) 바로 다음에 둔다. 이렇게 나눠지는 노드들을 리프 노드라고 불리며, 그중 딱 한개의 값을 가지는 걸 순수 노드(Pure node)라고 부른다,.
-장.단점 : 진행과정이 눈에 보인다는 점과 특별한 전처리(특성 정규화 or 표준화)가 불필요하다는  장점이 있지만, 복잡도를 제어해주지 않으면 과대적합되기 쉽다. 그래서 가지치기가 필요한데 이미 만들어진 모델 모듈에서는 사전 가지치기(max_dep , n_item 제한)만 가능합니다. 또한 트리기반 회귀모델은 외삽(외부 데이터 예측)이 불가능하다.

- 위의 과대적합을 피하기 위해 여러 개의 모델을 묶어주는 것이 앙상블입니다. 직관은 각각의 모델이 특정 데이터에 과대적합을 일으켜도, 그 모델들을 합쳐주면 일반화가 이뤄질 것이라는 것입니다.

